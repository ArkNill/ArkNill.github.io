---

layout: post

Title:  "2020.10.14 Big Data Debate"

---

## Big Data Debate

![](https://i.imgur.com/T0fzF1P.jpg)

_ _ _

## 토론회 필기 내용



- - -



## NAVER(자연어처리 책임리더 강인호)

#### 네이버 학습셋 구축

_ _ _


##### 수동으로 작성하는것을 자동으로

- 작성된 문서와 메타 정보를 활용하여 학습

```cpp

ex)

블로그 카테고리 분류

뉴스 카테고리 분류

지식인 질의 주제 분류

상품평/영화평 분류 (별 개수 추정)

지식인 제목 생성

```



- - -





##### 테스크 정의에 맞게 직접 혹은 용역으로 구축

```cpp

NLU - domain, intention, slot

NET - 네이버DB 대상 x News & Encylopedia

Sentiment Analysis - 긍/부정, 테마, 속성

Semantic Matching - 두 표현의 검색 의도 일치 판별

Summarization - 기계적인 방법의 품질 평가

```



- - -

##### **문제점**

데이터 세트를 만들어 서비스 제공시 사용자의 선호도는

매번 바뀌기 때문에 이에 유의해야한다.

```cpp

ex)

원피스 - 남자의 경우 일본만화, 여자의 경우 옷

시그널 - 게임 서비스,트와이스의 노래,드라마 제목

```



- - -

N-gram

BERT : 네이버의 파파고도 버트를 활용하여 사용



##### GPT3 - money game

- 1회 수행에 수십억 소요 예상



#### Zero-shot learning, one shot learning

- 학습셋 구축이 어려운 태스크에 적절

- 아직 서비스 운영하기에는 부담이 됨, 그러나 곧 해결되지 싶음

잼라이브: 3지선다 평가 20문제중 12개 성공(60%)

#### Aggregate Performance Across Bechmarks
![](http://)
- - -

### 풍요속의 빈곤

결과적으로는 데이터의 저작권과 개인정보 이슈에 따라
개발에 있어 제약사항이 많음
데이터의 개인화에 따른 성능 향상은 기대되지만
개인의 데이터를 공유화 하기는 쉽지 않을것이다.

- - -
### 향후 예상
형태소 해석 -> Pre training & Tokenizer Updating
Gigantic Language Model - GPT4
Privacy Preserving AI - Federated Learning
Multimodal - Language & Vision

- - -
### 끝맺음
모두의 말뭉치에 이어서
Pre-training & Tokenizer Updating도 지원되면
중복 투자가 많이 줄어들 것으로 예상한다.

++차후 추가++

- - -

##NCSOFT(NLP센터 이연수 실장)

++차후 추가++

- - -

##Saltlux(이경일 대표)

++차후 추가++

- - -

##Q&A

++차후 추가++

